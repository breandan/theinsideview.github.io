---
layout: post
title: "Charlie Snell on DALL-E and CLIP"
category: podcast
permalink: charlie
youtubeId: gcwidpxeAHI
spotifyId: 0zmaXDagxIowdtpARQH4uT
---

{% include youtubePlayer.html id=page.youtubeId %}
{% include spotifyPlayer.html id=page.spotifyId %}


We talk about AI generated art with Charlie Snell, a Berkeley researcher who [wrote](https://ml.berkeley.edu/blog/) extensively about AI art. We look at multiple slides with art throughout our conversation, so I highly recommend watching the video.

In the first part we go through Charlie's explanations of DALL-E, a model trained end-to-end by OpenAI to generate images from prompts.

We then talk about CLIP + VQGAN, where CLIP is another model by OpenAI matching prompts and images, and VQGAN is a state-of-the art GAN used extensively in the AI Art scene.

At the end of the video we look at different pieces of art made using CLIP, including tricks for using VQGAN with CLIP, videos, and the latest CLIP-guided diffusion architecture. At the end of our chat we talk about scaling laws and how progress in art relates to other advances in ML.